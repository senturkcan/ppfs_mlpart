{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "843d0307",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c42f540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, balanced_accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6322a6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess(file_path,target_column_index,has_header,delete_list,extraction_list):\n",
    "    \"\"\"this function is used for taking the dataset from .csv file making a test train split\n",
    "    and x, y split (has header is either True or False)\"\"\"\n",
    "\n",
    "    #reading the .csv\n",
    "    if has_header:\n",
    "        df = pd.read_csv(file_path, header=0, delimiter=\",\")  # First row as header\n",
    "        print(f\"Dataset shape: {df.shape}\")\n",
    "        print(f\"Column names: {list(df.columns)}\")\n",
    "    else:\n",
    "        df = pd.read_csv(file_path, header=None, delimiter=\",\")  # No header row\n",
    "        print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "    # Find all string/object columns automatically\n",
    "    string_columns = df.select_dtypes(include=['object']).columns\n",
    "    print(string_columns)\n",
    "    # Encode all string columns\n",
    "    for column in string_columns:\n",
    "        encoder = LabelEncoder()\n",
    "        df[column] = encoder.fit_transform(df[column])\n",
    "\n",
    "    df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    #making target variable split\n",
    "    x_first = df_shuffled.drop(df.columns[target_column_index], axis=1)  # All except target\n",
    "\n",
    "    x_ds = x_first.drop(columns = delete_list + extraction_list)\n",
    "    y_ds = df_shuffled.iloc[:, target_column_index]  # Target column only\n",
    "    \n",
    "\n",
    "    print(f'shape of x: {x_ds.shape}')\n",
    "\n",
    "    return x_ds, y_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "200180b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from docx.shared import Pt\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "\n",
    "def implement(model, x_ds, y_ds):\n",
    "    from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    scoring = ['balanced_accuracy', 'accuracy', 'precision_weighted', 'recall_weighted']\n",
    "    cv_results = cross_validate(model, x_ds, y_ds, cv=skf, scoring=scoring)\n",
    "    return cv_results \n",
    "\n",
    "def compute_model_differences(model_name, globals_dict):\n",
    "    \"\"\"\n",
    "    Creates variables like knn_0_precision, knn_1_precision, etc.\n",
    "    Each value formatted as: '+0.011' or '-0.002' or '0'\n",
    "    \"\"\"\n",
    "    metrics = {\n",
    "        \"bacc\": \"balanced_accuracy\",\n",
    "        \"precision\": \"precision_weighted\",\n",
    "        \"recall\": \"recall_weighted\"\n",
    "    }\n",
    "    \n",
    "    for i in range(0, 8, 2):  # pairs: (0,1), (2,3), (4,5), (6,7)\n",
    "        idx = i // 2\n",
    "        cv_a = globals_dict[f\"cv_results{i+1}\"]\n",
    "        cv_b = globals_dict[f\"cv_results{i+2}\"]\n",
    "        \n",
    "        for short, metric in metrics.items():\n",
    "            var_name = f\"{model_name}_{idx}_{short}\"\n",
    "            mean_a = cv_a[f\"test_{metric}\"].mean()\n",
    "            mean_b = cv_b[f\"test_{metric}\"].mean()\n",
    "            diff = round(mean_b - mean_a, 3)\n",
    "            \n",
    "            if diff == 0:\n",
    "                formatted = \"0\"\n",
    "            else:\n",
    "                sign = \"+\" if diff > 0 else \"\"\n",
    "                formatted = f\"{sign}{diff:.3f}\"\n",
    "            \n",
    "            globals_dict[var_name] = formatted\n",
    "\n",
    "def create_comparison_table(model_names, globals_dict, output_file=\"model_comparison.docx\"):\n",
    "    \"\"\"\n",
    "    Creates a Word table with models as columns and metrics as rows.\n",
    "    \n",
    "    Args:\n",
    "        model_names: List of model names (e.g., ['knn', 'svm', 'rf', 'dt', 'nb', 'lr'])\n",
    "        globals_dict: Dictionary containing all the model metric variables\n",
    "        output_file: Output Word document filename\n",
    "    \"\"\"\n",
    "    doc = Document()\n",
    "    doc.add_heading('Model Performance Comparison', 0)\n",
    "    \n",
    "    # Calculate number of rows: 4 datasets Ã— 2 metrics (precision, recall) = 8 rows + 1 header\n",
    "    num_datasets = 4\n",
    "    num_rows = num_datasets * 2 + 1  # +1 for header\n",
    "    num_cols = len(model_names) + 1  # +1 for metric names column\n",
    "    \n",
    "    # Create table\n",
    "    table = doc.add_table(rows=num_rows, cols=num_cols)\n",
    "    table.style = 'Light Grid Accent 1'\n",
    "    \n",
    "    # Header row\n",
    "    header_cells = table.rows[0].cells\n",
    "    header_cells[0].text = 'Metric'\n",
    "    for col_idx, model_name in enumerate(model_names):\n",
    "        header_cells[col_idx + 1].text = model_name.upper()\n",
    "        header_cells[col_idx + 1].paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "    \n",
    "    # Fill in the rows\n",
    "    row_idx = 1\n",
    "    for dataset_idx in range(num_datasets):\n",
    "        # Precision row\n",
    "        table.rows[row_idx].cells[0].text = f'Dataset {dataset_idx} - Precision'\n",
    "        for col_idx, model_name in enumerate(model_names):\n",
    "            var_name = f\"{model_name}_{dataset_idx}_precision\"\n",
    "            value = globals_dict.get(var_name, \"N/A\")\n",
    "            table.rows[row_idx].cells[col_idx + 1].text = str(value)\n",
    "            table.rows[row_idx].cells[col_idx + 1].paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "        row_idx += 1\n",
    "        \n",
    "        # Recall row\n",
    "        table.rows[row_idx].cells[0].text = f'Dataset {dataset_idx} - Recall'\n",
    "        for col_idx, model_name in enumerate(model_names):\n",
    "            var_name = f\"{model_name}_{dataset_idx}_recall\"\n",
    "            value = globals_dict.get(var_name, \"N/A\")\n",
    "            table.rows[row_idx].cells[col_idx + 1].text = str(value)\n",
    "            table.rows[row_idx].cells[col_idx + 1].paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "        row_idx += 1\n",
    "    \n",
    "    # Save document\n",
    "    doc.save(output_file)\n",
    "    print(f\"Table saved to {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68b2693",
   "metadata": {},
   "source": [
    "Select the dataset!\n",
    "\n",
    "Runs the preprocess for diffrent datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65c5cd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (13611, 17)\n",
      "Column names: ['Area', 'Perimeter', 'MajorAxisLength', 'MinorAxisLength', 'AspectRation', 'Eccentricity', 'ConvexArea', 'EquivDiameter', 'Extent', 'Solidity', 'roundness', 'Compactness', 'ShapeFactor1', 'ShapeFactor2', 'ShapeFactor3', 'ShapeFactor4', 'Class']\n",
      "Index(['Class'], dtype='object')\n",
      "shape of x: (13611, 16)\n"
     ]
    }
   ],
   "source": [
    "x_ds1, y_ds1 = preprocess(\"beans_kmeans.csv\", 16, True, [], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "184a7454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (13611, 17)\n",
      "Column names: ['Area', 'Perimeter', 'MajorAxisLength', 'MinorAxisLength', 'AspectRation', 'Eccentricity', 'ConvexArea', 'EquivDiameter', 'Extent', 'Solidity', 'roundness', 'Compactness', 'ShapeFactor1', 'ShapeFactor2', 'ShapeFactor3', 'ShapeFactor4', 'Class']\n",
      "Index(['Class'], dtype='object')\n",
      "shape of x: (13611, 11)\n"
     ]
    }
   ],
   "source": [
    "x_ds2, y_ds2 = preprocess(\"beans_kmeans.csv\", 16, True, [],[\"ShapeFactor2\",\"Compactness\",\"ShapeFactor3\",\"roundness\", \"MajorAxisLength\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5888940",
   "metadata": {},
   "source": [
    "x_ds, y_ds = preprocess(\"diabetes_kmeans.csv\", 8, True, [], [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c5a670",
   "metadata": {},
   "source": [
    "x_ds, y_ds = preprocess(\"diabetes_kmeans.csv\", 8, True, [], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92cab410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (170, 55)\n",
      "Column names: ['Atr1', 'Atr2', 'Atr3', 'Atr4', 'Atr5', 'Atr6', 'Atr7', 'Atr8', 'Atr9', 'Atr10', 'Atr11', 'Atr12', 'Atr13', 'Atr14', 'Atr15', 'Atr16', 'Atr17', 'Atr18', 'Atr19', 'Atr20', 'Atr21', 'Atr22', 'Atr23', 'Atr24', 'Atr25', 'Atr26', 'Atr27', 'Atr28', 'Atr29', 'Atr30', 'Atr31', 'Atr32', 'Atr33', 'Atr34', 'Atr35', 'Atr36', 'Atr37', 'Atr38', 'Atr39', 'Atr40', 'Atr41', 'Atr42', 'Atr43', 'Atr44', 'Atr45', 'Atr46', 'Atr47', 'Atr48', 'Atr49', 'Atr50', 'Atr51', 'Atr52', 'Atr53', 'Atr54', 'Class']\n",
      "Index([], dtype='object')\n",
      "shape of x: (170, 54)\n"
     ]
    }
   ],
   "source": [
    "x_ds3, y_ds3 = preprocess(\"divorce.csv\", 54, True, [], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed001548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (170, 55)\n",
      "Column names: ['Atr1', 'Atr2', 'Atr3', 'Atr4', 'Atr5', 'Atr6', 'Atr7', 'Atr8', 'Atr9', 'Atr10', 'Atr11', 'Atr12', 'Atr13', 'Atr14', 'Atr15', 'Atr16', 'Atr17', 'Atr18', 'Atr19', 'Atr20', 'Atr21', 'Atr22', 'Atr23', 'Atr24', 'Atr25', 'Atr26', 'Atr27', 'Atr28', 'Atr29', 'Atr30', 'Atr31', 'Atr32', 'Atr33', 'Atr34', 'Atr35', 'Atr36', 'Atr37', 'Atr38', 'Atr39', 'Atr40', 'Atr41', 'Atr42', 'Atr43', 'Atr44', 'Atr45', 'Atr46', 'Atr47', 'Atr48', 'Atr49', 'Atr50', 'Atr51', 'Atr52', 'Atr53', 'Atr54', 'Class']\n",
      "Index([], dtype='object')\n",
      "shape of x: (170, 39)\n"
     ]
    }
   ],
   "source": [
    "x_ds4, y_ds4 = preprocess(\"divorce.csv\", 54, True, [], ['Atr29','Atr8','Atr5','Atr22','Atr38','Atr40','Atr23','Atr52','Atr54','Atr32','Atr33','Atr34','Atr35','Atr36','Atr37'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f054b17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (195, 24)\n",
      "Column names: ['name', 'MDVP:Fo(Hz)', 'MDVP:Fhi(Hz)', 'MDVP:Flo(Hz)', 'MDVP:Jitter(%)', 'MDVP:Jitter(Abs)', 'MDVP:RAP', 'MDVP:PPQ', 'Jitter:DDP', 'MDVP:Shimmer', 'MDVP:Shimmer(dB)', 'Shimmer:APQ3', 'Shimmer:APQ5', 'MDVP:APQ', 'Shimmer:DDA', 'NHR', 'HNR', 'status', 'RPDE', 'DFA', 'spread1', 'spread2', 'D2', 'PPE']\n",
      "Index(['name'], dtype='object')\n",
      "shape of x: (195, 22)\n"
     ]
    }
   ],
   "source": [
    "x_ds5, y_ds5 = preprocess(\"parkinsons_kmeans.csv\", 17, True, ['name'], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0209cca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (195, 24)\n",
      "Column names: ['name', 'MDVP:Fo(Hz)', 'MDVP:Fhi(Hz)', 'MDVP:Flo(Hz)', 'MDVP:Jitter(%)', 'MDVP:Jitter(Abs)', 'MDVP:RAP', 'MDVP:PPQ', 'Jitter:DDP', 'MDVP:Shimmer', 'MDVP:Shimmer(dB)', 'Shimmer:APQ3', 'Shimmer:APQ5', 'MDVP:APQ', 'Shimmer:DDA', 'NHR', 'HNR', 'status', 'RPDE', 'DFA', 'spread1', 'spread2', 'D2', 'PPE']\n",
      "Index(['name'], dtype='object')\n",
      "shape of x: (195, 16)\n"
     ]
    }
   ],
   "source": [
    "x_ds6, y_ds6 = preprocess(\"parkinsons_kmeans.csv\", 17, True, ['name'], ['spread1','HNR','PPE','MDVP:APQ','NHR','MDVP:Jitter(Abs)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd2af581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (3810, 8)\n",
      "Column names: ['Area', 'Perimeter', 'Major_Axis_Length', 'Minor_Axis_Length', 'Eccentricity', 'Convex_Area', 'Extent', 'Class']\n",
      "Index(['Class'], dtype='object')\n",
      "shape of x: (3810, 7)\n"
     ]
    }
   ],
   "source": [
    "x_ds7, y_ds7 = preprocess(\"rice_binned_kmeans.csv\", 7, True, [], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1930ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (3810, 8)\n",
      "Column names: ['Area', 'Perimeter', 'Major_Axis_Length', 'Minor_Axis_Length', 'Eccentricity', 'Convex_Area', 'Extent', 'Class']\n",
      "Index(['Class'], dtype='object')\n",
      "shape of x: (3810, 5)\n"
     ]
    }
   ],
   "source": [
    "x_ds8, y_ds8 = preprocess(\"rice_binned_kmeans.csv\", 7, True, [], ['Minor_Axis_Length', 'Extent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d39b8d",
   "metadata": {},
   "source": [
    "x_ds, y_ds = preprocess(\"wdbc_binned_kmeans.csv\", 1, True, ['ID'], [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced61ffe",
   "metadata": {},
   "source": [
    "x_ds, y_ds = preprocess(\"wdbc_binned_kmeans.csv\", 1, True, ['ID'], [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a658522",
   "metadata": {},
   "source": [
    "Run the implement function for diffrent models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73d08b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "cv_results1 = implement(KNeighborsClassifier(),\n",
    "                     x_ds1, y_ds1)\n",
    "\n",
    "cv_results2 = implement(KNeighborsClassifier(),\n",
    "                     x_ds2, y_ds2)\n",
    "\n",
    "cv_results3 = implement(KNeighborsClassifier(),\n",
    "                     x_ds3, y_ds3)\n",
    "\n",
    "cv_results4 = implement(KNeighborsClassifier(),\n",
    "                     x_ds4, y_ds4)\n",
    "\n",
    "cv_results5 = implement(KNeighborsClassifier(),\n",
    "                     x_ds5, y_ds5)\n",
    "\n",
    "cv_results6 = implement(KNeighborsClassifier(),\n",
    "                     x_ds6, y_ds6)\n",
    "\n",
    "cv_results7 = implement(KNeighborsClassifier(),\n",
    "                     x_ds7, y_ds7)\n",
    "\n",
    "cv_results8 = implement(KNeighborsClassifier(),\n",
    "                     x_ds8, y_ds8)\n",
    "\n",
    "\n",
    "compute_model_differences(\"knn\", globals())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60134b84",
   "metadata": {},
   "source": [
    "knn_0_bacc= round(cv_results2['test_balanced_accuracy'].mean() - cv_results1['test_balanced_accuracy'].mean(), 3)\n",
    "knn_1_bacc= round(cv_results4['test_balanced_accuracy'].mean() - cv_results3['test_balanced_accuracy'].mean(), 3)\n",
    "knn_2_bacc= round(cv_results6['test_balanced_accuracy'].mean() - cv_results5['test_balanced_accuracy'].mean(), 3)\n",
    "knn_3_bacc= round(cv_results8['test_balanced_accuracy'].mean() - cv_results7['test_balanced_accuracy'].mean(), 3)\n",
    "\n",
    "knn_0_precision= round(cv_results2['test_precision_weighted'].mean() - cv_results1['test_precision_weighted'].mean(), 3)\n",
    "knn_1_precision= round(cv_results4['test_precision_weighted'].mean() - cv_results3['test_precision_weighted'].mean(), 3)\n",
    "knn_2_precision= round(cv_results6['test_precision_weighted'].mean() - cv_results5['test_precision_weighted'].mean(), 3)\n",
    "knn_3_precision= round(cv_results8['test_precision_weighted'].mean() - cv_results7['test_precision_weighted'].mean(), 3)\n",
    "\n",
    "knn_0_recall= round(cv_results2['test_recall_weighted'].mean() - cv_results1['test_recall_weighted'].mean(), 3)\n",
    "knn_1_recall= round(cv_results4['test_recall_weighted'].mean() - cv_results3['test_recall_weighted'].mean(), 3)\n",
    "knn_2_recall= round(cv_results6['test_recall_weighted'].mean() - cv_results5['test_recall_weighted'].mean(), 3)\n",
    "knn_3_recall= round(cv_results8['test_recall_weighted'].mean() - cv_results7['test_recall_weighted'].mean(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27c4bcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\VS Code Projects\\ppfs_mlpart\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "e:\\VS Code Projects\\ppfs_mlpart\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "#Ada Boost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "cv_results1 = implement(AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "                     x_ds1, y_ds1)\n",
    "\n",
    "cv_results2 = implement(AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "                     x_ds2, y_ds2)\n",
    "\n",
    "cv_results3 = implement(AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "                     x_ds3, y_ds3)\n",
    "\n",
    "cv_results4 = implement(AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "                     x_ds4, y_ds4)\n",
    "\n",
    "cv_results5 = implement(AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "                     x_ds5, y_ds5)\n",
    "\n",
    "cv_results6 = implement(AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "                     x_ds6, y_ds6)\n",
    "\n",
    "cv_results7 = implement(AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "                     x_ds7, y_ds7)\n",
    "\n",
    "cv_results8 = implement(AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "                     x_ds8, y_ds8)\n",
    "\n",
    "compute_model_differences(\"ada\", globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fba3aeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\VS Code Projects\\ppfs_mlpart\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "e:\\VS Code Projects\\ppfs_mlpart\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "from sklearn.svm import SVC \n",
    "cv_results1 = implement(SVC(max_iter = -1, random_state=42),\n",
    "                     x_ds1, y_ds1)\n",
    "\n",
    "cv_results2 = implement(SVC(max_iter = -1, random_state=42),\n",
    "                     x_ds2, y_ds2)\n",
    "\n",
    "cv_results3 = implement(SVC(max_iter = -1, random_state=42),\n",
    "                     x_ds3, y_ds3)\n",
    "\n",
    "cv_results4 = implement(SVC(max_iter = -1, random_state=42),\n",
    "                     x_ds4, y_ds4)\n",
    "\n",
    "cv_results5 = implement(SVC(max_iter = -1, random_state=42),\n",
    "                     x_ds5, y_ds5)\n",
    "\n",
    "cv_results6 = implement(SVC(max_iter = -1, random_state=42),\n",
    "                     x_ds6, y_ds6)\n",
    "\n",
    "cv_results7 = implement(SVC(max_iter = -1, random_state=42),\n",
    "                     x_ds7, y_ds7)\n",
    "\n",
    "cv_results8 = implement(SVC(max_iter = -1, random_state=42),\n",
    "                     x_ds8, y_ds8)\n",
    "\n",
    "compute_model_differences(\"svm\", globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c80a70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "\n",
    "cv_results1 = implement(GaussianNB(),\n",
    "                     x_ds1, y_ds1)\n",
    "\n",
    "cv_results2 = implement(GaussianNB(),\n",
    "                     x_ds2, y_ds2)\n",
    "\n",
    "cv_results3 = implement(GaussianNB(),\n",
    "                     x_ds3, y_ds3)\n",
    "\n",
    "cv_results4 = implement(GaussianNB(),\n",
    "                     x_ds4, y_ds4)\n",
    "\n",
    "cv_results5 = implement(GaussianNB(),\n",
    "                     x_ds5, y_ds5)\n",
    "\n",
    "cv_results6 = implement(GaussianNB(),\n",
    "                     x_ds6, y_ds6)\n",
    "\n",
    "cv_results7 = implement(GaussianNB(),\n",
    "                     x_ds7, y_ds7)\n",
    "\n",
    "cv_results8 = implement(GaussianNB(),\n",
    "                     x_ds8, y_ds8)\n",
    "\n",
    "compute_model_differences(\"gnb\", globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c072b9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forests\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "cv_results1 = implement(RandomForestClassifier(),\n",
    "                     x_ds1, y_ds1)\n",
    "\n",
    "cv_results2 = implement(RandomForestClassifier(),\n",
    "                     x_ds2, y_ds2)\n",
    "\n",
    "cv_results3 = implement(RandomForestClassifier(),\n",
    "                     x_ds3, y_ds3)\n",
    "\n",
    "cv_results4 = implement(RandomForestClassifier(),\n",
    "                     x_ds4, y_ds4)\n",
    "\n",
    "cv_results5 = implement(RandomForestClassifier(),\n",
    "                     x_ds5, y_ds5)\n",
    "\n",
    "cv_results6 = implement(RandomForestClassifier(),\n",
    "                     x_ds6, y_ds6)\n",
    "\n",
    "cv_results7 = implement(RandomForestClassifier(),\n",
    "                     x_ds7, y_ds7)\n",
    "\n",
    "cv_results8 = implement(RandomForestClassifier(),\n",
    "                     x_ds8, y_ds8)\n",
    "\n",
    "compute_model_differences(\"rf\", globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "816975ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decesion Trees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "cv_results1 = implement(DecisionTreeClassifier(),\n",
    "                     x_ds1, y_ds1)\n",
    "\n",
    "cv_results2 = implement(DecisionTreeClassifier(),\n",
    "                     x_ds2, y_ds2)\n",
    "\n",
    "cv_results3 = implement(DecisionTreeClassifier(),\n",
    "                     x_ds3, y_ds3)\n",
    "\n",
    "cv_results4 = implement(DecisionTreeClassifier(),\n",
    "                     x_ds4, y_ds4)\n",
    "\n",
    "cv_results5 = implement(DecisionTreeClassifier(),\n",
    "                     x_ds5, y_ds5)\n",
    "\n",
    "cv_results6 = implement(DecisionTreeClassifier(),\n",
    "                     x_ds6, y_ds6)\n",
    "\n",
    "cv_results7 = implement(DecisionTreeClassifier(),\n",
    "                     x_ds7, y_ds7)\n",
    "\n",
    "cv_results8 = implement(DecisionTreeClassifier(),\n",
    "                     x_ds8, y_ds8)\n",
    "\n",
    "compute_model_differences(\"dt\", globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28538d00",
   "metadata": {},
   "source": [
    "Comparison results for futher use at LaTex table format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30e35947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table saved to model_comparison.docx\n"
     ]
    }
   ],
   "source": [
    "model_names = ['knn', 'svm', 'rf', 'dt', 'nb', 'lr']\n",
    "\n",
    "# Compute differences for each model\n",
    "for model_name in model_names:\n",
    "    compute_model_differences(model_name, globals())\n",
    "\n",
    "# Create the Word table\n",
    "create_comparison_table(model_names, globals(), \"model_comparison.docx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
