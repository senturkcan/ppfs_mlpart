{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25028203",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import jinja2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7a3255",
   "metadata": {},
   "source": [
    "reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de2bd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file_path,has_header):\n",
    "    \"\"\"this function is used for taking the dataset from .csv file making a test train split\n",
    "    and x, y split (has header is either True or False)\"\"\"\n",
    "\n",
    "    #reading the .csv\n",
    "    if has_header:\n",
    "        df = pd.read_csv(file_path, header=0, delimiter=\",\")  # First row as header\n",
    "        print(f\"Dataset shape: {df.shape}\")\n",
    "        print(f\"Column names: {list(df.columns)}\")\n",
    "    else:\n",
    "        df = pd.read_csv(file_path, header=None, delimiter=\",\")  # No header row\n",
    "        print(f\"Dataset shape: {df.shape}\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c218bad",
   "metadata": {},
   "source": [
    "selecting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d53110",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name= \"beans\"\n",
    "df = read_csv(dataset_name + \"_kmeans.csv\", True)\n",
    "label_column = 16\n",
    "number_of_sets = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1246d40d",
   "metadata": {},
   "source": [
    "dataset_name= \"diabetes\"\n",
    "df = read_csv(dataset_name + \"_kmeans.csv\", True)\n",
    "label_column = 8\n",
    "number_of_sets = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3ad47d",
   "metadata": {},
   "source": [
    "dataset_name= \"divorce\"\n",
    "df = read_csv(dataset_name + \".csv\", True)\n",
    "label_column = 54\n",
    "number_of_sets = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff315bfb",
   "metadata": {},
   "source": [
    "dataset_name= \"parkinsons\"\n",
    "df = read_csv(dataset_name + \"_kmeans.csv\", True)\n",
    "df = df.drop(columns = 'name')\n",
    "label_column = 16\n",
    "number_of_sets = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd898a60",
   "metadata": {},
   "source": [
    "dataset_name= \"rice\"\n",
    "df = read_csv(dataset_name + \"_binned_kmeans.csv\", True)\n",
    "label_column = 7\n",
    "number_of_sets = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1590871e",
   "metadata": {},
   "source": [
    "dataset_name= \"wdbc\"\n",
    "df = read_csv(dataset_name + \"_binned_kmeans.csv\", True)\n",
    "df = df.drop(columns = 'ID')\n",
    "label_column = 0\n",
    "number_of_sets = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006fe81d",
   "metadata": {},
   "source": [
    "making string columns numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88fc608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all string/object columns automatically\n",
    "string_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Encode all string columns\n",
    "for column in string_columns:\n",
    "    encoder = LabelEncoder()\n",
    "    df[column] = encoder.fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8900ca1b",
   "metadata": {},
   "source": [
    "mi for all features (graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a79435",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plt.style.available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793e73f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mi_for_all(df_name = df, lc = label_column, title = 'complete dataset'):\n",
    "    y = df_name.iloc[:, lc]\n",
    "    #print(f'label is {y}')\n",
    "    x = df_name.drop(df_name.columns[lc], axis=1)\n",
    "    mi_scores = mutual_info_classif(x, y, discrete_features=True)\n",
    "    mi_scores= mi_scores / np.log(2)\n",
    "\n",
    "\n",
    "\n",
    "    #   ********   multiplied with -1 for the elbow method graphs\n",
    "    #mi_scores= mi_scores * -1\n",
    "\n",
    "    \n",
    "    mi_df = pd.DataFrame({\"Feature\": x.columns, \"MI_Score\": mi_scores}).sort_values(by=\"MI_Score\", ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Create line plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.plot(mi_df[\"Feature\"], mi_df[\"MI_Score\"], marker='o')\n",
    "    ax.set_xlabel(\"Features\")\n",
    "    ax.set_ylabel(\"MI Values\")\n",
    "    ax.set_title(f\"Mutual Information Scores {dataset_name.title()} Dataset\")\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'mi {dataset_name} {title}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return x,y,mi_df\n",
    "\n",
    "x,y,mi_df= mi_for_all()\n",
    "mi_df.to_latex(f'{dataset_name}_mi.tex', index=True, float_format='%.6f')\n",
    "print(mi_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d66535",
   "metadata": {},
   "source": [
    "vertical split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f545ccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target columns count (divide into 3 parts, take integer)\n",
    "#total_columns = df.shape[1]\n",
    "#target_columns_count = total_columns // 3\n",
    "# Pick random feature columns from total number of columns from dataset x\n",
    "#random.seed(42)\n",
    "#random_cols = random.sample(range(x.shape[1]), target_columns_count - 1)\n",
    "# Build target_set (label first, then random features)\n",
    "#target_features = x.iloc[:, random_cols]\n",
    "#target_set = pd.concat([y, target_features], axis=1)\n",
    "#remaining_set = x.drop(x.columns[random_cols], axis=1)\n",
    "#print(\"Target columns count:\", target_columns_count)\n",
    "#print(\"Selected feature indices:\", random_cols)\n",
    "#print(target_set.head(), \"\\n\")\n",
    "#print(remaining_set.head())\n",
    "\n",
    "# Split the feature indices into groups\n",
    "parts = np.array_split(np.arange(df.shape[1]), number_of_sets, axis=0)\n",
    "\n",
    "# Get the first group of feature indices\n",
    "#target_feature_indices = parts[0]\n",
    "\n",
    "# Select the target features using column indices\n",
    "#target_features = x.iloc[:, target_feature_indices]\n",
    "\n",
    "# Create target set by concatenating y with target features\n",
    "#target_set = pd.concat([y, target_features], axis=1)\n",
    "print(\"Parts:\")\n",
    "for i, part in enumerate(parts):\n",
    "    print(f\"Part {i}: {part}\")\n",
    "\n",
    "target_set = None\n",
    "\n",
    "# Find which part has the label column and get that part\n",
    "for part in parts:\n",
    "    if label_column in part:\n",
    "        target_set = df.iloc[:, part]\n",
    "        break\n",
    "\n",
    "if target_set is not None:\n",
    "    print(f\"Target set shape: {target_set.shape}\")\n",
    "else:\n",
    "    print(f\"Label column {label_column} not found in any part\")\n",
    "\n",
    "\n",
    "\n",
    "#make label first column on target_set and the last column will be the lowst mi on target_set\n",
    "label_col = df.columns[label_column]\n",
    "col_data = target_set.pop(label_col)  # Remove the column\n",
    "target_set.insert(0, label_col, col_data)  # Insert it at position 0\n",
    "\n",
    "\n",
    "# Create remaining set by dropping the target feature columns\n",
    "#remaining_set = x.drop(x.columns[target_feature_indices], axis=1)\n",
    "\n",
    "#print(\"Selected feature indices:\", target_feature_indices)\n",
    "\n",
    "#print(\"Remaining set shape:\", remaining_set.shape)\n",
    "#print(remaining_set.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3912733",
   "metadata": {},
   "source": [
    "mi on the set with label to find the target (lowest mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e6f36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MI scores and find lowest MI column\n",
    "a,b,target_mi_df = mi_for_all(df_name=target_set, lc=0, title = 'in target set')\n",
    "\n",
    "lowest_mi_column = target_mi_df.iloc[-1]['Feature']\n",
    "print(f\"Column with lowest MI: {lowest_mi_column}\")\n",
    "\n",
    "# Calculate Spearman correlations\n",
    "lowest_mi_data = target_set[lowest_mi_column]\n",
    "print(f\"lowest_mi_data:{lowest_mi_data}\")\n",
    "\n",
    "#x_ranked = x.rank(method='average').astype(int)\n",
    "#lowest_mi_ranked = lowest_mi_data.rank(method='average').astype(int)\n",
    "\n",
    "correlations = x.corrwith(lowest_mi_data, method='spearman')\n",
    "\n",
    "# Convert to DataFrame and sort\n",
    "corr_df = pd.DataFrame({\n",
    "    'Feature': correlations.index,\n",
    "    'Spearman_Correlation': correlations.abs().values\n",
    "}).sort_values('Spearman_Correlation', ascending=False)\n",
    "\n",
    "# Remove the column that correlates with itself\n",
    "corr_df = corr_df[corr_df['Feature'] != lowest_mi_column]\n",
    "\n",
    "\n",
    "print(f\"Spearman correlations between '{lowest_mi_column}' and x:\")\n",
    "print(corr_df)\n",
    "\n",
    "# Create line plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.plot(corr_df[\"Feature\"], corr_df[\"Spearman_Correlation\"], marker='o')\n",
    "ax.set_xlabel(\"Features\")\n",
    "ax.set_ylabel(\"Abs. Corrolation Values\")\n",
    "ax.set_title(f\"Target= {lowest_mi_column} Feature Corrolations {dataset_name.title()} Dataset\")\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{dataset_name} spearman correlation.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "corr_df.to_latex(f'{dataset_name}_corr.tex', index=True, float_format='%.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1863d4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = corr_df.reset_index(drop=True)\n",
    "corr_df['diffrence'] = corr_df['Spearman_Correlation'].diff(1)\n",
    "corr_df['change'] = corr_df['diffrence'].diff(1) * -1\n",
    "print(corr_df['change'])\n",
    "print(np.argmin(corr_df['change']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf83c0e8",
   "metadata": {},
   "source": [
    "\"\"\"corr_df = corr_df.reset_index(drop=True)\n",
    "\n",
    "print(corr_df)\n",
    "corr_df['diffrence'] = corr_df['Spearman_Correlation'].diff(-1)\n",
    "#corr_df['diffrence'] = corr_df['diffrence'] +1\n",
    "print(corr_df)\n",
    "\n",
    "corr_df[\"ratio\"] = corr_df['diffrence'].shift(-1) / corr_df['diffrence']\n",
    "\n",
    "#corr_df['ratio'] = corr_df['ratio'] -1\n",
    "#corr_df['ratio'] = corr_df['ratio'] * 100\n",
    "\n",
    "print(corr_df)\n",
    "\"\"\"\n",
    "df_excel = corr_df.copy()\n",
    "\n",
    "# Flatten MultiIndex columns\n",
    "if isinstance(df_excel.columns, pd.MultiIndex):\n",
    "    df_excel.columns = [\"_\".join(map(str, c)) for c in df_excel.columns]\n",
    "\n",
    "# Preserve index if meaningful\n",
    "df_excel = df_excel.reset_index()\n",
    "\n",
    "df_excel.to_excel(\n",
    "    \"diff.xlsx\",\n",
    "    sheet_name=\"beans\",\n",
    "    index=False,\n",
    "    float_format=\"%.10f\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a245cc",
   "metadata": {},
   "source": [
    "CHANGE İÇİN CONSTRAİNLİ EN YÜKSEĞİ EL baştan %10 sondan %50 sonra pozisyon bazlı Exponential Mechanishm uygula. DP sağlar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2462e9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = corr_df[corr_df[\"change\"].notna()]\n",
    "n = len(valid_df)\n",
    "start_idx = int(n * 0.10)\n",
    "end_idx = int(n * 0.50)\n",
    "\n",
    "elbow_index = (valid_df.iloc[start_idx:end_idx][\"change\"].idxmin()) -1\n",
    "print(elbow_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
